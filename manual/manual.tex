\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{psfrag}
\usepackage{color}

\newcommand{\mtt}[1]{\mbox{\tt #1}}
\input /users/davidmcallester/03/tex/nofill.tex

\newcommand{\fopen}{{\color{red} \langle}}
\newcommand{\fclose}{{\color{red} \rangle}}

\newcommand{\ignore}[1]{}

\parskip = 2ex
\parindent = 0ex

\newcommand{\context}{\text{\emph{context}}}

\title{MetaC 1.0}
\author{David McAllester}

\setcounter{tocdepth}{2}

\begin{document}
\maketitle

\begin{abstract}
  MetaC provides a read-eval-print loop (a REPL) and notebook interactive development environment (a NIDE) for C programming.
  MetaC can also be described as a Lisp-inspired programming environment for C.
  The REPL and the NIDE  are capable of incrementally compiling and executing
  C statements and incremental procedure definitions in a persistent C process.  This is done by compiling and loading dynamic load libraries.

  MetaC also extends C with Lisp-like features. More specifically, MetaC provides a C-like universal syntax,
  computed macros, backquote~\cite{backquote}, and pattern-matching.
  The implementation is bootstrapped --- it is implemented in itself.  These C extensions are intended to support the development of high level
  frameworks with notebook interfaces as direct extensions of C.  This is in contrast to scripting-C hybrids such as Matlab, Numpy, TensorFlow or PyTorch.

  The NIDE is implemented in Emacs piped to a MetaC REPL.  Presumably notebook IDEs for C or C++ could also be implemented as extensions
  of Atom or Visual Studio Code piped to a persistent process.

  Dynamic linking is difficult to implement robustly.
  MetaC release 1.0 runs under both Ubuntu 18.04.1 / gcc 7.3.0 and MAC OSX 10.11.4 / gcc Apple LLVM version 7.3.0 (clang-703.0.31).
\end{abstract}

\vfill
\noindent {\bf Acknowledgement:}  I would like to thank Bob Givan for his aid in exercising and polishing MetaC and his continuing efforts on MathZero.
\newpage

\tableofcontents

\newpage

\section{Introduction and Overview}

\subsection{Installation}

\noindent To install the REPL:

\begin{enumerate}
\item Clone the MetaC repository in a local MetaC directory.
\item From a shell running in your MetaC directory type make MC.
\item From the same shell type MC to get the command line prompt MC$>$.
\end{enumerate}

\noindent To install the NIDE:

\begin{enumerate}
\item Clone the repository into a repository directory.
\item From a shell running in your MetaC directory type make NIDE.
\item Add {\tt (load "$<$MetaC directory$>$/mc.el")} to your .emacs file.
\item Edit the first line of  mc.el to give the path to your gdb executable (the Gnu debugger).
\item Edit the second line of mc.el to give the path to your MetaC directory.
\item Start or restart Emacs. The file mc.el adds hooks such that it is safest to restart Emacs rather than load em.el into a running Emacs.
\end{enumerate}

\noindent The NIDE can be run on any file with extension .mc in any directory.  To experiment with the NIDE use Emacs to visit the file NIDE-examples.mc from the MetaC repository.  
Type C-M-s (control-meta-s) to start (or restart) the C kernel. Typing C-c C-c will run the cell containing the cursor and print
the result in a C comment at the bottom of the cell.  This is substantially equivalent to typing the cell contents into the REPL.
More Emacs key bindings and other features of the NIDE are described in section~\ref{sec:Emacs}.

\medskip
\noindent The following examples use the REPL.  However, all of these examples can be run as cells in the NIDE.

\subsection{Hello World}
\label{sec:hello}

\begin{verbatim}
bash$ make MC
...

bash$ MC

MC> `{hello world}

hello world

MC>
\end{verbatim}

In the above example the backquote expression given to the REPL macro-expands to a C expression which evaluates to the expression ``hello world''.
Backquote is described in more detail below.

\subsection{C Statements and C Expressions}

We can also declare global variables and execute statements from the REPL.

\begin{verbatim}
MC> int x[10];

done

MC> for(int i = 0; i < 10; i++)x[i] = i;

done


MC> for(int i = 0; i < 10; i++)fprintf(stdout,"%d",x[i]);

0123456789done

MC>int_exp(x[5])

5

MC>
\end{verbatim}

In C syntax one distinguishes C expressions from C statements.  A C
statement is executed for effect while a C expression is evaluated for
value. The REPL can be given either a statement or an expression.  When
given a C statement, the REPL simply prints ``done'' after executing
the statement.
When given a C expression the REPL computes and prints
the value.  The REPL assumes that the value of a C expression
is a universal syntax tree (also called an expression, giving a second, and confusing,
sense of the term ``expression''). The procedure {\tt int\_exp} above
converts an integer to a universal syntax expression.  Universal syntax expressions are abstract
syntax trees but can viewed as representations of strings.

If a C statement executes a {\tt return} outside of any
procedure then that value is returned to the REPL and printed.
For example, the above session can be extended with the following.

\begin{verbatim}
MC>{int sum = 0; for(int i = 0; i < 10; i++)sum += x[i]; return int_exp(sum);}

45

MC>
\end{verbatim}

\subsection{Definitions of Types and Procedures}

One can also define new data types and procedures from the REPL.

\begin{verbatim}

MC>typedef struct myexpstruct{
   char * label;
   struct myexpstruct * car;
   struct myexpstruct * cdr;} myexpstruct, *myexp;

done

MC> myexp mycons(char*s,myexp x,myexp y){
    myexp cell=malloc(sizeof(myexpstruct));
    cell->label=s;
    cell->car=x;
    cell->cdr=y;
    return cell;}

done

MC> expptr myexp_exp(myexp x){
   if(x==NULL)return string_atom("nil");
   return
    `{${string_atom(x->label)}
      ${myexp_exp(x->car)}
      ${myexp_exp(x->cdr)}};
}

done

MC> myexp_exp(mycons("foo",mycons("bar",NULL,NULL),NULL))


foo bar nil nil nil
MC>
\end{verbatim}

Procedures can also be redefined at the REPL provided that the
signature (argument types and return type) remains the same. Changing a procedure signature
requires restarting the MetaC REPL.  This restricting ensures
meaningful C type checking in the presence of dynamic linking.

\subsection{The Global Variable Array Restriction}

To simplify dynamaic linking, all global data
variables must be arrays. One can always use single element
arrays to represent non-array variables.  To make this more convenient
we allow single element arrays to be declared with an initial value in a
manner similar to non-array data variables.  For example, we can declare and assign a variable {\tt y}
as follows.

\begin{verbatim}
MC> int y[0] = 2;

done

MC> y[0] += 1;

done

MC> int_exp(y[0])

3

MC>
\end{verbatim}

Here assignments to $y[0]$ are allowed but assignments to $y$ are not --- assignment to array variables
are not allowed in $C$. As noted above, this restriction greatly simplifies dynamic linking of data variables.

\subsection{The Single Symbol Type Restriction}

To simplify the implementation of MetaC all type expressions appearing in procedure signatures and global array declarations must be single symbols.
Arbitrary types can be given single symbol names using {\tt typedef}.

\subsection{Backquote and Universal Syntax}

We now consider backquote and universal syntax in more detail.  Backquote can be used in a manner analogous to string formatting.

\begin{verbatim}
MC> expptr friend[0] = `{Bob Givan};

done

MC> int height[0] = 6;

done

MC> `{My friend ${friend[0]} is ${int_exp(height[0])} feet tall.}

My friend Bob Givan is 6 feet tall.

MC> 
\end{verbatim}

While universal syntax expressions can be viewed as representations of strings, universal syntax
expressions are actually abstract syntax trees. The tree structure
plays an important role in pattern matching. The tree structure is
more apparent in the following example.

\begin{verbatim}
MC> expptr e[0] = `{a+b};

done

MC> `{bar(${e[0]})}

bar(a+b)

MC>
\end{verbatim}

As described in the next section, the pattern {\tt foo($\$$x)} will match the expression {\tt foo(a+b)} with {\tt x} bound to the expression (tree) {\tt a+b}.

\subsection{Pattern Matching}

MetaC provides a pattern matching case construct {\tt ucase} (universal case).
The general form of the case construct is

\begin{verbatim}
ucase{e;
  {<pattern1>}:{<body1>}
   ...
  {<patternn>}:{<bodyn>}}
\end{verbatim}

Variables are marked in patterns by the prefix $\$$.

\begin{verbatim}

MC>int numeralp(expptr x)
    {if(!atomp(x))return 0;
    char*s=atom_string(x);
    for(int i=0;s[i]!='\0';i++){if(s[i]<'0'||s[i]>'9')return 0;}
    return 1;
}

done

MC> int value(expptr e)
  {ucase
    {e;
      {$x+$y}:{return value(x)+value(y);}
      {$x*$y}:{return value(x)*value(y);}
      {($x)}:{return value(x);}
      {$z}.(numeralp(z)):{return atoi(atom_string(z));}
    }
  return 0; //this dead code convinces the compiler there is a return value.
  }

done

MC>int_exp(value(`{5+2*10}))

25

MC>int_exp(value(`{foo}))


 match error: the value 


foo
does not match any of


{$z}.(numeralp(z)){($x)}{$x*$y}{$x+$y}

MC>
\end{verbatim}

In many situations the choice of the particular tree structure imposed by the MetaC reader is not important as long as the same conventions are used in both the patterns and the expressions
they are matching.  For example, the expression {\tt a+b+c} will match the pattern
{\tt $\$$x+$\$$y+$\$$z} independent of whether + is left associative or right associative.  But the tree structure does matter in other cases.  The pattern {\tt $\$$x*$\$$y}
will not match the expression {\tt a+b*c} because the reader brackets {\tt a+b*c} as  $\fopen \mathtt{a~+} \fopen \mathtt{b * c} \fclose\fclose$. The pattern {\tt $\$$x*$\$$y} does match {\tt (a+b)*c}.
The variable {\tt $\$$any} is special.  It acts as a wild card and is not bound to a value.

When a {\tt ucase} is executed the patterns are tried sequentially and stops after the first match.  If no pattern matches an error is generated.
One can always add a final pattern of {\tt \{$\$$any\}} to provide a default
catch-all case if that is desired.

In release 1.0 repeated variables, such as in the pattern {\tt \{$\$$x + $\$$x\}}, are not supported (and not checked for).
If a variable is repeated it will be matched at its last occurrences under depth-first left to right traversal.

\subsection{Gensym and Macro Definitions}

MetaC supports computed macros.  Pattern matching and backquote greatly facilitate the writing of computed macros.  Backquote and ucase are both implemented as computed macros in the bootstrapped implementation. As a very simple example we can define a {\tt dolist} macro at the REPL.

\begin{verbatim}

MC>umacro{dolist($x,$L){$body}}{
   expptr rest=gensym("rest");
   return
    `{for(expptr $rest = $L; cellp($rest); $rest = cdr($rest);){
      expptr $x=car($rest);
      $body}};
}

done

MC>macroexpand(`{dolist(item,list){f(item);}})

for
  (expptr _genrest33=list;
   cellp(_genrest33);
  _genrest33=cdr(_genrest33);
  ){expptr item=car(_genrest33);f(item);}

MC>
\end{verbatim}

The general form of a macro definition is
\begin{verbatim}
umacro{<pattern>}{<body>}
\end{verbatim}
where instances of {\tt <pattern>} in MetaC code are to be replaced by
the value returned by {\tt <body>} under the variable bindings
determined by the match.  The pattern is restricted so as to have
an identifiable head symbol to which the macro is attached.
The procedure {\tt macroexpand(exptr e)} takes a
universal syntax expression and returns the result of repeatedly
expanding outermost macros until no further macro expansion is
possible.

The macro expansion of the above definition of {\tt dolist}
defines a procedure
to compute the macro expansion and installs that procedure on a macro
property of the symbol {\tt dolist}.  A typical macro pattern
is a symbol followed by one or more parenthesis
expressions in which case the macro is attached to the initial symbol.
The pattern can also be
a binary connective expressions such as {\tt {$x .> $y}}.  In this case
the macro is attached to the connective.

\subsection{The Notebook IDE}
\label{sec:Emacs}

Starting the kernel with the key C-M-s creates a running C process.  When a cell is executed
with the command C-c C-c the text of the cell is (invisibly) passed to $C$ process and a value returned
y the process is printed inside a comment below the cell.  If a comment already occurs directly below the cell this
comment is replaced by a new comment containing the response of the REPL.  As in a Jupyter notebook,
the values returned from the REPL are numbered so that one can see when the cell was executed
relative to other cell execution in the notebook.  If C-M-s is run when a kernel is already running
the kernel process is killed and a new one started (as in a Jupyter notebook).  When the kernel is
restarted the execution numbering is reset to start with 1.  Changing a procedure signature
(argument and return types) requires restarting the kernel.

{\bf Cell Boundaries.}
A cell begins at any nonempty line whose first character is other than white space (space or tab), a close character ')', '\}', or ']', or a slash '/'.
The cell ends at the begging of the next non-empty line whose first character is other than white space or a a close character.  Note that a comment
starting at the beginning of a line terminates a cell.

\noindent {\bf Errors and Breakpoints.}
If an error occurs while macro-expanding a cell the NIDE will print {\tt "expansion error"} and enter the gdb debugger.  Typing the command {\tt continue}
to gdb will return to the NIDE.
If an error occurs while attempting to compile the macro-expanded expanded cell the NIDE will print {\tt "compilation error''} and display the output of the compiler.

The MetaC procedure {\tt berror(char *)} enters the gdb debugger. When gdb is invoked in this way typing the {\tt continue} command
will return to the NIDE (or REPL) with the C process intact. MetaC primitives call {\tt berror} when safety checks fail.
The MetaC procedure {\tt breakpt(char *)} can be used for breakpoints from which execution can be continued.  When {\tt breakpt} is called
the NIDE will invoke the debugger and typing the command {\tt continue} will continue the execution from the breakpoint.

Segmentation faults, and other types of errors, are trapped by gdb directly.  In this case the
NIDE will enter the gdb debugger.  However, in this case the normal gdb continue command will not return to the code buffer.
To recover one types {\tt print NIDE()} to gdb which will typically
return to the code buffer with the persistent C process intact.  MetaC is designed to minimize the possibility of memory corruption
when returning from an error.  See the discussions of unwind protection in sections~\ref{sec:memory} and \ref{sec:undo}.
But if there is a concern over memory corruption one can always restart the C process.

\noindent {\bf Printing.} The procedure {\tt mcprint} is like {\tt fprintf} but omitting the file argument. The expression
{\tt mcprint("x = \%s$\backslash$n",s)} will print to the *Messages* buffer in Emacs. The procedure {\tt mcpprint(expptr e)}
will pretty-print the expression $e$ to the *Messages* buffer.  When in the gdb debugger the procedure {\tt dbpprint(expptr e)} will
pretty print an expression in the gdb REPL.

\noindent {\bf Key Bindings.}  mc.el provides the following key bindings.

\begin{itemize}
\item[C-M-s] starts or restarts the persistent C process.

\item[C-c C-c] executes the cell containing the cursor.
  
\item[C-c C-r] executes all cells in the current region sequentially with a different execution number for each cell execution.

\item[C-M-a] moves to the begging of the current cell.

\item[C-M-p] moves to the beginning of the preceding cell.

\item[C-M-n] moves to the beginning of the next cell.

\item[C-M-c] removes all cell values.  This is useful before a git commit as it can reduce or eliminate differences
in files between commits.
\end{itemize}

{\bf Include Statements.}  A cell in a code file containing {\tt \#include($<$filename$>$)} (with no semicolon) will load the cells of the named
file into the persistent C process.  The extension ".mc" will be automatically added and should not be explicitly given.



\section{Miscellaneous Features}

\subsection{Interning and Properties}

In MetaC expressions are interned and have property lists.
Interning means that two expressions which have the same tree structure and sequence of leaves --- that are ``equal'' in Lisp terminology --
represented by the same data structure with the same memory address --- are ``eq''.
Hence we have
\begin{verbatim}
MC> int_exp(`{foo(a)} == `{foo(a)})
1
\end{verbatim}
Interned expressions with properties provide the functionality of dictionary data structures such as C++ hashmaps or Python dictionaries.
Interning also facilitates the implementation of forward chaining inference algorithms --- we do not want to waste noticing the same
consequence over and over again.  Interned expressions with property lists can be viewed as a form of no-SQL database.
Interning also allows directed acyclic graphs (dags) to be represented compactly as expressions.  This is very convenient
for the representation of machine-generated justifications (proofs).

The procedure {\tt setprop(expptr exp, expptr prop, void * value)}
sets the given property of the given expression to the given value.  The procedure {\tt getprop(expptr exp, expptr prop, void * default)}
the given property of the given value or the default value if no property value has been assigned.
MetaC also provides the procedures {\tt setprop\_int(expptr e, expptr p, int n)} and {\tt getprop\_int(expptr e, expptr p, int default)}.
It is not difficult to define polymorphic macros for setting and extracting properties where the type of the property is passed as an argument.
It is also not difficult to assign types to particular properties so that the type argument is not needed in polymorphic property setting and retrieving.
However, these features are not present in release 1.0.

\subsection{Memory Frames}
\label{sec:memory}

A memory frame is analogous to a stack frame but is only sparsely tied to the C stack.
The macro {\tt in\_memory\_frame($<$statement$>$)} will execute the given statement inside a new memory frame.
The procedure {\tt stack\_alloc(int nbytes)}
returns a pointer to a block of the given size allocated from the current memory frame. When {\tt in\_memory\_frame($<$statement$>$)}  exits
the memory-frame free pointer (or ``stack pointer'') is reset.  This frees all memory allocated from the frame.
This architecture differs from traditional stack allocation in that recursive procedures can operate with a single memory frame and return newly allocated memory as values
without copying.  The allocated storage will not be deallocated until exit from an enclosing use of {\tt in\_memory\_frame}.
MetaC pre-allocates the heap (stack space) used for memory frames.  The deallocation (resetting of the freeptr) is unwind protected and will occur
when an error is thrown beyond the frame entry point.  This avoids a memory leak when returning from the an error to the REPL or NIDE.


\subsection{Undo Frames}
\label{sec:undo}
Undo frames are similar to memory frames but with the added feature of undoing effects tied to the frame.
The macro {\tt exp\_from\_undo\_frame($<$expression$>$)} creates a new undo frame and executes the given expression
in the new frame. Memory is allocated from the current undo frame
with the procedure {\tt undo\_alloc(int nbytes)}.  Effect are tied to the current undo frame with the C preprocessor macro
{\tt undo\_set(void * loc, void * val)}.  On exit from an undo frame all memory allocated from that frame are reclaimed by resetting a free pointer
and all locations assigned by {\tt undo\_set} are restored to the values they had before entry to the frame.

In MetaC all expression allocation and property assignments are tied to the current undo frame.
On exit from the undo frame the database represented by expression properties is restored to
the state that existing on frame entry.

The macro {\tt exp\_from\_undo\_frame($<$expression$>$)} computes the value of the given expression in the new frame, then pops that undo frame while
copying the computed value into the parent undo frame.  The value must be a universal syntax expression
(an expptr). This is used for returning the ``value'' or ``result'' of a large computation while freeing the allocation and undoing the effects of the computation.
The macro {\tt exp\_from\_undo\_frame($<$expression$>$)} has unwind protection so that the undo frame is popped (with memory deallocated and effects undone)
if an error is thrown in the execution of the expression.

The procedure {\tt clean\_undo\_frame(expptr e)} is similar to {\tt exp\_from\_undo\_frame} but replaces the current undo frame with a fresh one
into which the given expression is copied.  In this case there is no allocation from the parent frame.
The procedure {\tt clean\_undo\_frame(expptr e)} can be used for garbage collection
as in {\tt (install\_live\_stuff(clean\_undo\_frame(compute\_live\_stuff())))}.

The procedures {\tt exp\_from\_undo\_frame} and {\tt clean\_undo\_frame} both run in time proportional to the dag size of the
given expression. The dag size can be exponentially smaller than the tree size.

\subsection{Bootstrapping and File Expansion}
\label{sec:bootstrap}

MetaC is bootstrapped.  The makefile for MetaC includes the following.
\begin{verbatim}
mcB.c : expandA mcB.mc
	 ./expandA mcB.mc mcB.c
\end{verbatim}
The executable {\tt expandA} is implemented entirely in $C$ but implements the backquote macro.  The executable {\tt expandA}
expands backquote expressions appearing in the input file. The file {\tt mcB.mc} implements {\tt ucase} using backquote
and the excutable expandB expands both backquote expressions and ucase statements.
The makefile also includes.
\begin{verbatim}
mcC.c : expandB mcC.mc
	 ./expandB mcC.mc mcC.c
\end{verbatim}
Here the file {\tt mcC.mc} implements additional macros using both backquote and ucase.  In the MetaC makefile this is continued up to mcE.mc and expandE.
MetaC provides the procedure
{\tt mcexpand(char * f1, char * f2)} which is used in the code for the expand commands.  This procedure macro-expands the
file {\tt f1} and writes the result to file {\tt f2}.  This macro-expansion is done using whatever procedures and operators currently
have macro expansion procedure pointers on their property lists, i.e., the expansion is done using whatever macros are defined in the current state.

The procedure {\tt mcexpand(char * f1, char * f2)} is implemented using the MetaC procedure {\tt file\_expressions(char * f)}.
This procedure takes a file name and returns a list of the expressions contained in the cells of that file.

\subsection{Macro Effects}

Macros expansion can have effects.  The macro {\tt umacro} expands to a procedure definition of the macro expansion code but also
generates a statement which installs that procedure pointer in the macro property of the head symbol.  During macro expansion the
MetaC primitive {\tt add\_init\_form(expptr statement)} is called with a statement that installs the procedure pointer on the appropriate property list.

In file expansion the initialization forms generated during macro expansion are incorporated into an initialization procedure.
The macro {\tt init\_fun(<fname>)} macro expands to a definition of the given procedure name with no arguments but with the sequence
of initialization forms in its body.  In the REPL and IDE the initialization forms are run before the macro expansion of the input or cell is run.

\subsection{Macro Preliminary Definitions}

Macro expansion can also generate preliminary definitions.  It is possible to implement syntactic closures (lambda) as a macro.
A closure consists of a procedure pointer together with values for the free variables in the body of the lambda expression.  The lambda
macro must first create the procedure that executes the body of the lambda expression and then incorporate that procedure pointer into
the expansion of lambda macro.  The construction of the procedure definition is a ``preamble'' to the macro expansion.
MetaC provides the primitive {\tt add\_preamble(expptr definition)} for creating preambles during macro expansion.
In file expansion these preamble definitions are inserted into the output file before the
expression generated by the macro.  In the REPL and NIDE these preamble definitions are installed along with the expression created by the macro.
MetaC 1.0 supports preambles but does not provide a macro for lambda expressions.

\section{Universal Syntax}

It is not obvious how to implement light weight expression quotation and expression pattern matching for C expressions.  The syntax of C is complex.
We bypass this complexity by introducing a syntax with the following three ``universal'' properties.

\begin{enumerate}
\item Universal syntax trees are semantics-free.  They are simply trees viewed as representations of character strings.

\item The universal syntax reader can read any parenthesis-balanced character string.
  Here parenthesis-balanced means that every open parenthesis, brace or bracket has a matching closing character and that string quotations
  are properly closed.
  
\item The printer inverts the reader. If we read a string $s$ into a universal syntax expression
  $e$ and then print $e$ back into a string $s'$ we have that $s$ and $s'$ are equivalent in a strong sense.  Here we want
  $s$ and $s'$ to be ``whitespace equivalent'' so as to be treated equivalently by the C lexer.
\end{enumerate}

The emphasis here is on the representation of strings.  The reader does not always invert the printer ---
the expression $\fopen \fopen \mathtt{one~two} \fclose \;\mathtt{three}\fclose$ prints as {\tt one two three} which reads as
$\fopen \mathtt{one}\; \fopen \mathtt{two~three} \fclose \fclose$.  But the represented string is preserved.  This is fundamentally different from
most programming languages supporting symbolic computation (such as Lisp) where it is assumed that the tree structure, rather than the represented string, is fundamental
and hence that the reader should invert the printer.

The above universality properties allow one to assign semantics to universal syntax expressions based on the strings that they represent.  We can assign C
semantics to an expression by printing the expression and passing the resulting string to a C compiler.  This string-based semantics is not always
compositional with respect to the universal syntax tree structure.  However, the tree structure imposed by the reader is designed to approximate the
compositional structure of C syntax.  In most cases pattern matching on universal syntax expressions recovers substructure that is semantically compositional under C
semantics. Parentheses and semicolons can be helpful in aligning universal syntax trees with C semantics.
For languages and frameworks implemented as macro packages in MetaC one can guarantee that the universal syntax tree structure
has compositional semantics.

\subsection{Universal Expressions: cons-car-cdr}

A universal syntax expression is either an atom (a wrapper around a string),
a pair $\fopen e_1 e_2 \fclose$ where $e_1$ and $e_2$ are expressions, or a ``parenthesis expression'' the form $(e)$,
$\{ e\}$, or $[e]$ where $e$ is an expression.   All three of these datatypes have the same C type {\tt expptr} (Expression Pointer).
For each of the types atom, pair and parenthesis expression there is a constructor procedure, a predicate, and accessor functions as follows.

\begin{verbatim}
expptr string_atom(char *);
int atomp(expptr);
char * atom_string(expptr); //the argument must be an atom.

expptr cons(expptr,expptr);
int cellp(expptr);
expptr car(expptr); //the argument must be a cell. returns the first component.
expptr cdr(expptr); //the argument must be a cell. returns the second component.

expptr intern_paren(char,expptr); // the char must be one of '(', '{' or '['
int parenp(expptr);
expptr paren_inside(expptr);
\end{verbatim}

\subsection{Universal Expressions: Phantom Brackets}

The MetaC reader maps a character string to a universal syntax expression.  A specification of the reader is given in section~\ref{sec:reader}.
The expression produced by the reader
can be represented by ``phantom brackets'' around the given string
where there is a pair of brackets for each cons cell.
For example the expression \mtt{\{one two three\}} reads as $\{\fopen \mathtt{one}\;\fopen \mathtt{two~three}\fclose \fclose\}$.
Examples of strings and the phantom bracking imposed by the reading those strings is given in figure~{\ref{fig:reader}}.
The printer simply removes the phantom brackets and prints the string that the expression represents.

To reduce the clutter of brackets we will adopt two conventions for supressing brackets when exhibiting phantom brackets.
The first convention is the Lisp right-branching convention of not showing all the cell brackets for right-associative (right-branching) sequences.
For example $\fopen \mathtt{zero}\;\fopen \mathtt{one}\;\fopen \mathtt{two~three}\fclose \fclose \fclose$.
will be written as $\fopen\mathtt{zero~one~two~three}\fclose$.  Note that these ``lists'' are atom-terminated rather than the Lisp convention of
nil termination.

The second convention is that we will sometimes write $\fopen \fopen a_1 \;o\fclose\;a_2\fclose$ where $o$ is a connective atom
as the left-branching structure $\fopen a_1\;o\;a_2 \fclose$.  For example, the expression \mtt{\{a + b\}} reads as
$\{\fopen \fopen \mathtt{a~+} \fclose \;\mathtt{b} \fclose \}$ which is then abbreviated as
$\{\fopen \mathtt{a~+~b} \fclose \}$.  Left-branching for binary connectives gives a
C-consistent treatment of semicolon as a binary connective while also supporting the interpretation of semicolon as a statement terminator.
This is discussed in more detail below.

It will generally be clear from context whether we using the Lisp right-branching list convention
or the left-branching connective convention.
A set of examples of strings and the phantom brackets generated by the reader is given in figure~\ref{fig:reader}.


To emphasize the significance of left-branching binary connectives we note that
the MetaC reader bracketing of
$$\{e_1\;;\;e_2\;;\;e_3\;;\;e_4\}$$
can be written using either the left-braching binary connective convention as
$$\{\fopen e_1\;;\;\fopen e_2\;;\;\fopen e_3\;;\;e_4\fclose\fclose\fclose\}$$
or the right-braching sequence convention as
$$\{\fopen \fopen e_1\;;\fclose \;\fopen e_2\;;\fclose \;\fopen e_3\;;\fclose\;e_4\fclose\},$$
both of which abbreviate the same full bracketing
$$\{\fopen \fopen e_1\;;\fclose \;\fopen \fopen e_2\;;\fclose \;\fopen \fopen e_3\;;\fclose\;e_4\fclose\fclose\fclose\}.$$

\begin{figure}
\begin{eqnarray*}
  \mathtt{Hello~World} & \Rightarrow & \fopen \mathtt{Hello}\;\; \mathtt{World}\fclose \\
  \mathtt{one~two~three} & \Rightarrow & \fopen \mathtt{one}\;\; \fopen \mathtt{two} \; \;\mathtt{three}\fclose\fclose \\
   & = & \fopen \mathtt{one~two~three} \fclose \\
  \mathtt{x~+~y} & \Rightarrow & \fopen\fopen \mathtt{x~+}\fclose\;\mathtt{y}\fclose \\
  & = & \fopen \mathtt{x~+~y} \fclose \\
  \mathtt{x+y*z} & \Rightarrow & \fopen \mathtt{x~+}\; \fopen \mathtt{y~*~z} \fclose\fclose \\
  \mathtt{(x+y)*z} & \Rightarrow & \fopen (\fopen \mathtt{x~+~y} \fclose )\;\mathtt{*~z}\fclose \\
  \mathtt{foo}(\mathtt{int~x}) & \Rightarrow & \fopen \mathtt{foo}\; (\fopen \mathtt{int}\;  \; \mathtt{x}\fclose)\fclose \\
  \mathtt{foo(int~x,~float~y)} & \Rightarrow & \fopen \mathtt{foo} \; (\fopen\fopen \mathtt{int}\; \mathtt{x} \fclose\;
  \mathtt{,}\; \fopen\mathtt{float} \; \mathtt{y} \fclose\fclose )\;\fclose
\end{eqnarray*}

\caption{{\bf Examples of Reader Bracketings.} Bracketings are shown for the expression that results form reading the given strings.
  A complete bracketing shows a pair of brackets for every expression pair (cons cell).
  The second and third example show two somewhat informal conventions for dropping some of the brackets --- general sequences are
  assumed to be right-associative and binary connective applications are assumed to be left-associative.  These conventions are used in other examples.
  Expressions are printed without the brackets --- the brackets are ``phantoms'' that show the tree structure.   The bracketing (parsing) done by the reader
  is specified formally in section~\ref{sec:reader}. Since the bracketing does not affect the represented string, the precise bracketing is often unimportant.}
\label{fig:reader}
\end{figure}


\subsection{The Reader Specification}
\label{sec:reader}

The MetaC reader can be described in three phases --- preprocessing, lexicalization, and parsing.

The MetaC preprocessor replaces each C-style comment with a space character.  When processing an entire file,
as is done in the MetaC procedure {\tt file\_expressions}
described in section~\ref{sec:bootstrap}, the preprocessor divides the file in cells using the same conventions as is used in the NIDE.
A file must be parenthesis-balanced within each cell.

Lexicalization segments a pre-processed character sting into to a sequence of atoms.
The MetaC lexer preserves all non-white characters.  For the MetaC lexer each atom is one of the following.

\begin{itemize}
\item Symbols.  A symbol is a character string consisting of only alpha-numeric characters --- upper and lower case letters of the alphabet, plus the decimal numerals, plus underbar.
  For example {\tt foo\_bar1}.
\item Connectives.  A connective is a character string consisting of only ``connective characters'' --- the connective characters consist of all non-alphanumeric, non-white, non-parenthesis, characters
  other than the three special characters {\tt \$}, {\tt `} and $\backslash$.
\item Quoted strings.  A character string starting and ending with the same string quotation character.  For example {\tt "foo bar"}, {\tt "!:\&?;"} or {\tt 'a'}.
\item Special character atoms. These are atoms whose strings are one character long where that character is one of
  the special characters $\mtt{`}$, $\mtt{\$}$, and $\backslash$.
\end{itemize}

Two strings will be called whitespace-equivalent if they lexicalize to the same sequence of atoms.

\newcommand{\sym}{\mathrm{SYM}}
\newcommand{\conn}{\mathrm{CONN}}
\newcommand{\quot}{\mathrm{QUOTE}}
\newcommand{\misc}{\mathrm{MISC}}
\newcommand{\app}{\mathrm{APP}}
\newcommand{\var}{\mathrm{VAR}}


The reader is specified by a the grammar shown in figure~\ref{fig:grammar}.
To simplify the specification of the reader we enclose the given string in parentheses so that, without loss of generality, the input is assumed to be of the form
$\{s\}$ where $s$ is the lexical sequence to be read.  The grammar has a nonterminal $P$ for parenthesis expression which we take as the top level nonterminal.
The nonterminals $\sym$ and $\quot$ range over alpha-numeric string atoms and quoted string atoms respectively.
For each positive integer $p$ we have a nonterminal $\conn_p$ ranging over connective atoms of precedence $p$.
We have a nonterminal $E_p$ for expressions formed with connectives
of precedence $p$.  We also has a nonterminal $E_\infty$ for expressions that are formed at higher precedence than any connective expression.
The precedence levels are divided into a set ${\cal L}$ of left-associative precedence levels and a set ${\cal R}$ of right associative precedence levels.
There is a special precedence level 3 for combining expressions with the ``null connective''. The null connective is left-associative.
The null connective is higher precedence that semicolon and comma but lower precedence than all other connectives.
The nonterminal $E_\infty$ includes an epsilon production allowing null arguments.

\begin{figure}
  
\begin{eqnarray*}
  P & ::= & (E_p) \;|\; \{E_p\} \;|\; [E_p] \\
  E_p & ::= & \fopen \fopen E_\ell\;\conn_p\fclose \;E_r\fclose\;\;\;\;p \in {\cal R}, \;\ell > p, \; r \geq p \\
  E_p & ::= & \fopen \fopen E_\ell\;\conn_p\fclose \;E_r\fclose\;\;\;\;p \in {\cal L}, \; \ell \geq p,\; r > p \\
  E_3 & ::= & \fopen E_\ell \;E_r\fclose \;\;\;\ell > 3,\;r \geq 3\\
  E_\infty & ::= & \quot \;|\; \fopen S \; \;P^* \fclose \;|\; \fopen `\;P\fclose \;|\; P \;|\; \epsilon \;|\; \mathrm{JUNK}\\
  S & ::= & \;\sym \;|\; \var \\
  \var & ::= & \fopen \$\;\sym\fclose \;|\; \fopen \$\;P\fclose \;|\; \fopen \backslash \; \var \fclose\\
  P^* & ::= &  \epsilon  \;|\; \fopen P\;P^* \fclose \\
  \mathrm{JUNK} & ::= & ` \;|\; \mathrm{SJUNK} \\
  \mathrm{SJUNK} & :: = & \$ \;|\;  \backslash \;|\; \fopen \backslash\;\mathrm{SJUNK} \fclose\\
\end{eqnarray*}

\caption{{\bf The grammar defining the MetaC reader.} The input string is assumed to be of the form $(s)$ so that endpoints are explicitly labeled.
The nonterminal $\sym$ generates non-empty alpha-numeric strings; $\conn_p$ generates non-empty connective
strings of precedence $p$; and $\quot$ generates string quotations.  ${\cal R}$ is a set of right-associative precedence levels and ${\cal L}$ is a set of left-associative levels.
Only the largest finite precedence level is left-associative. MetaC classifies all printable ASCII characters as being either alpha-numeric, connective, string quotations, parenthesis characters or one of the three special characters
{\tt `}, $\$$ or $\backslash$.
The reader will accept any parenthesis-balanced string. $\epsilon$ denotes the empty string. Generated cells of the form $\fopen w\;\epsilon \fclose$ or $\fopen \epsilon \;w\fclose$ are replaced by $w$.
Although the grammar is ambiguous, the reader is deterministic as specified by the constraints that
$E_\infty$ expressions must be maximal and that the use of the $\epsilon$ production for $E_\infty$ must be minimized.  See the text for details.
  }
\label{fig:grammar}
\end{figure}

The nonterminal $S$ ranges over symbols or variables where $\var$ ranges over variables.  Variables are handles specially in pattern matching ({\tt ucase}) and pattern instantiation (backquote).
Expression of the form $\fopen S\;P^*\fclose$ include {\tt foo}, {\tt foo(x)}, {\tt foo(int x)\{return x;\}},
{\tt \$x}, {\tt \$f(x)}, and {\tt \$\{f(x)\}}.


The above grammar is ambiguous.  For example the string {\tt \{foo (a) (b)\}} can be parsed as either the left-branching structure $\{\fopen\fopen\sym\;P^*\fclose\;P\fclose\}$
or the  right-branching structure $\{\fopen\sym\;P^*\fclose\}$.
The reader is of course deterministic --- {\tt \{foo (a) (b)\}} is read as right-branching.  While a deterministic grammar for the reader can be given, it is simpler
to specify a deterministic parsing process for the above ambiguous grammar.
The implementation runs a deterministic left-to-right shift-reduce process.
However, the parser is easier to specify as operating in global stages.  In the first stage one identifies all maximal $E_\infty$ substrings.
The maximal requirement implies that {\tt \{foo (a) (b)\}} is parsed as the single (right-branching)
$E_\infty$ expression $\fopen${\tt foo (a) (b)}$\fclose$. The maximil requirement also implies that the string {\tt \{$\$$\;foo\;(a)\;(b)\}} is read as the single $E_\infty$
expression $\fopen \fopen \mathtt{\$~foo}\fclose\ \mathtt{(a)~(b)} \fclose$.

After identifying maximal $E_\infty$ expressions we are left with a sequence of arguments (the $E_\infty$ expressions) and connectives.
However, it is possible that this sequence contains multiple consecutive connectives or multiple consecutive arguments.  We then place an argument between any two consecutive
connectives using the $\epsilon$ production for $E_\infty$ and also add an $\epsilon$ term at the beginning of the sequence if the sequence starts with a connective and an
epsilon argument at the end if the sequence ends in a connective.  We now have a sequence of arguments and connectives starting and ending with arguments and where there
are no two consecutive connectives.  Next set $k$ to be the largest precedence of any connective and form all the $E_k$ substrings. We then repeatedly decrement $k$ and identify all the $E_k$ substrings
until we have identifies all $E_p$ substrings for all $p$.  At this point the entire string must be parsed as $E_p$ where $p$ is the smallest precedence of the connectives
where we think of adjacent arguments as having an implicit precedence 4 connetive between them.

\noindent This process can parse any parenthesis-balanced string.

The above specification of the reader can result in cells of the form $\fopen e\;\epsilon \fclose$ or $\fopen \epsilon \;e\fclose$.   The implementation avoids producing such cells
and the reader can be viewed as replacing $\fopen e\;\epsilon \fclose$ or $\fopen \epsilon \;e\fclose$ by $e$ so that
all cells are of the form $\fopen e_1\;e_2\fclose$ where $e_1$ and $e_2$ are expressions representing non-empty strings.  An empty parenthesis string {\tt ()}
is read as a parenthesis expression containing an atom for the empty string.

\noindent Grouped by precedence, the binary connective characters are

\medskip
\centerline{\{\mtt{;}\} \{\mtt{,}\}  \{\mtt{|}\} \{$\epsilon$\}
  \{{\tt \&}, {\tt ?}, {\tt !}\} \{{\tt =} {\tt $\sim$}, {\tt $<$}, {\tt $>$}\} \{{\tt +}, {\tt -}\}
  \{{\tt *}, {\tt /}\} \{{\tt \%}, $\hat{~}$, {\tt .}\} \{\mtt{:},  {\tt @}, {\tt \#}\}.}

\noindent The precedence of a binary connective is determined by its first character.  The
characters have low to high (outer to inner) precedence in the order given with symbols in the same
group having the same precedence.  Here $\epsilon$ represents the null connective at precedence
level 4  The precedence can be summarized in outer to inner order as semicolon, comma, bar, the
null connective, Boolean connectives, binary predicates, three levels of binary functions, and
innermost connectives which can be viewed as providing a way of building structured atoms.  This
universal syntax precedence conventions has
various divergences with C syntax.  However, when writing a macro package in MetaC one can simply
adopt the MetaC precedence conventions for the source code and use parentheses where necessary in
the generated C code.

\subsection{Backquote and Pattern Matching Revisited}

The semantics of backquote is defined in terms of cons-car-cdr view of expressions independent of the MetaC reader.
In the typical case, the C value of a backquote expression
$\fopen ` \;\{e\}\fclose$ is the expression (tree) $e$ with subexpressions (subtrees) of the form $\fopen \$\;x \fclose$, where $x$ is a symbol,
replaced by the C value of $x$
and subexpressions (subtrees) of the form $\fopen \$\;\{w\}\fclose$ replaced by the expression which is the C value of the string represented by the expression $w$.

Unfortunately this evaluation rule for backquote expressions is incomplete.  One of the most
confusing situations is where the expansion of a macro contains a backquote.  Writing such a macro typically involves nested backquotes.  While nested backquotes
are confusing, and should be avoided when possible, MetaC supports nested backquotes.  We consider a series of backquote expressions each of which evaluates to the previous one.

First we have
\begin{equation}
\label{bq1}
`\{a+b+\$\{z\}\}
\end{equation}

If the value of variable {\tt z} is the expression {\tt c} then the value of expression (\ref{bq1}) is the expression {\tt a+b+c}.
The symbol {\tt \$} can be included in the value of a backquote expression by quoting it.  This gives our second expression.
\begin{equation}
\label{bq2}
`\{`\{a + \$\{y\} + \backslash\$\{z\}\}\}
\end{equation}

If the value of variable {\tt y} is the expression $b$ then the value expression of (\ref{bq2}) is expression (\ref{bq1}).
We can even have multiple layers of quotation as in the following.
\begin{equation}
\label{bq3}
`\{`\{`\{\$\{x\} + \backslash\$\{y\} + \backslash\backslash\$\{z\}\}\}\}
\end{equation}

If the value of variable {\tt x} is the expression {\tt a} then the value of expression (\ref{bq3}) is expression (\ref{bq2}).

As with backquote, pattern matching is defined in terms of the cons-car-cdr view of expressions independent of the MetaC reader.  We define a substitution to be a mapping from
symbol atoms to expressions. For a substitution $\sigma$ and a pattern $\{e\}$ we define the expressions $\sigma(e)$
to be the result of replacing each subexpression (subtree) of $e$ of the form $\fopen \$\;x \fclose$ where $x$ is a symbol atom with $\sigma(x)$.  A pattern expression (tree) $\{e\}$ matches an expression (tree) $w$ with substitution $\sigma$
if $\sigma(e) = w$. An exception to this is the case where a variable occurs multiple times in the pattern.  In release 1.0 multiple occurrences of a variable in a pattern is not supported.

\section{List of MetaC Primitives}

We now give a list of the MetaC primitives and pre-installed type definitions.  The macros backquote, ucase, and umacro expand to code built on these primitves.
We start with type definitions needed for the single atom type restriction needed for the limiting type parsing abilities of MetaC.

\begin{verbatim}
typedef char * charptr;
typedef void * voidptr;
typedef FILE * FILEptr;
typedef struct expstruct{...} * expptr;
\end{verbatim}

\subsection{Expressions}

The macros {\tt backquote} and {\tt ucase} expand into C code using these procedures.

\begin{verbatim}
expptr string_atom(charptr s);

int atomp(expptr e);

charptr atom_string(expptr a);

expptr cons(expptr x, expptr y);

int cellp(expptr e);

expptr car(expptr x);

expptr cdr(expptr x);

expptr intern_paren(char openchar, expptr arg); \\ openchar must be one of '(', '{' or '['.

int parenp(expptr e);

expptr paren_inside(expptr e);

char constructor(expptr e); //used for paren expressions.
\end{verbatim}

We also have integer-expression conversions.  The REPL and NIDE require that inputs and cells respectively are expression-valued.

\begin{verbatim}
expptr int_exp(int i);

int exp_int(expptr s);
\end{verbatim}

\subsection{Properties}

The macro {\tt umacro } expands to code that
sets the macro property of some atom to a procedure pointer.

\begin{verbatim}
void setprop(expptr e, expptr key, voidptr val);

expptr getprop(expptr e, expptr key, expptr defaultval);

expptr gensym(charptr s);
\end{verbatim}

\subsection{Errors and Breakpoints}

\begin{verbatim}
void berror(charptr s);

void breakpt(charptr s);

void NIDE();
\end{verbatim}

\subsection{Reading and Printing}
The procedure {\tt file\_expressions} takes a file name and returns a
list of the expressions (in universal syntax) contained in the cells
of the file.  The last two print to the emacs *Messages* buffer in
the NIDE.  The last expressions is a macro.

\begin{verbatim}
expptr file_expressions(charptr name);

void pprint(expptr e, FILEptr f, int indent); //indent is typically 0

void mcpprint(epptr e);

void mcprint(...)
\end{verbatim}

\subsection{Macro Expansion}

\begin{verbatim}
expptr macroexpand(expptr e);

expptr macroexpand1(expptr e); //this result may contain unexpanded macros

void add_init_form(expptr statement);

void add_preamble(expptr aux_definition);
\end{verbatim}

\subsection{List Processing}

\begin{verbatim}
expptr append(expptr l1, expptr l2);

expptr reverse(expptr l);

typedef  expptr exp_to_exp(expptr);
typedef  void exp_to_void(expptr);

expptr mapcar(exp_to_exp f, expptr l);

void mapc(exp_to_void f, expptr l);

int length(expptr l);
\end{verbatim}

\subsection{Memory Frames}

\begin{verbatim}
in_memory_frame(<statement>)

voidptr stack_alloc(int nbytes);
\end{verbatim}

\subsection{Undo Frames}

\begin{verbatim}
void exp_from_undo_frame(<expression>);

voidptr undo_alloc(int nbytes);

void undo_set(voidptr loc, voidptr val);

void clean_undo_frame(expptr e);
\end{verbatim}

\subsection{Bootstrapping and File Expansion}

\begin{verbatim}
file_expressions(char * fname);

mcexpand(char * fname1, char * fname2);

init_fun(fname)
\end{verbatim}

\bibliographystyle{abbrv}

\bibliography{manual}

\end{document}
