\documentclass{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{psfrag}
\usepackage{color}

\newcommand{\mtt}[1]{\mbox{\tt #1}}
\input /users/davidmcallester/03/tex/nofill.tex

\newcommand{\fopen}{{\color{red} \langle}}
\newcommand{\fclose}{{\color{red} \rangle}}

\newcommand{\ignore}[1]{}

\parskip = 2ex
\parindent = 0ex

\newcommand{\context}{\text{\emph{context}}}

\title{MetaC 1.0}
\author{David McAllester}

\setcounter{tocdepth}{2}

\begin{document}
\maketitle

\begin{abstract}
  MetaC provides a read-eval-print loop (a REPL) and notebook interactive development environment (a NIDE) for C programming.
  MetaC can also be described as a Lisp-inspired programming environment for C.
  The REPL and the NIDE  are capable of incrementally evaluating (compiling and running)
  C statements and incremental procedure definitions in a persistent C process.  This is implemented by incrementally compiling dynamic load libraries
  which are then linked into the persistent process.

  MetaC also extends C with Lisp-like features. More specifically, MetaC provides a C-like universal syntax,
  computed macros, backquote~\cite{backquote}, and pattern-matching.
  The implementation is bootstrapped --- it is implemented in itself.  These C extensions are intended to support the development of high level
  frameworks with notebook interfaces as direct extensions of C.  This is in contrast to scripting-C hybrids such as Matlab, Numpy, TensorFlow or PyTorch.

  The NIDE is implemented in Emacs piped to a MetaC REPL.  Presumably notebook IDEs for C or C++ could also be implemented as extensions
  of Atom or Visual Studio Code piped to a persistent process.

  Dynamic linking is difficult to implement robustly.
  MetaC release 1.0 runs under both Ubuntu 18.04.1 / gcc 7.3.0 and MAC OSX 10.11.4 / gcc Apple LLVM version 7.3.0 (clang-703.0.31).
\end{abstract}

\vfill
\noindent {\bf Acknowledgement:}  I would like to thank Bob Givan for his aid in exercising and polishing MetaC and his continuing efforts on MathZero.
\newpage

\tableofcontents

\newpage

\section{Introduction and Overview}

\subsection{Installation}

\noindent To install the REPL:

\begin{enumerate}
\item Clone the MetaC repository in a local MetaC directory.
\item From a shell running in your MetaC directory type make MC.
\item From the same shell type MC to get the command line prompt MC$>$.
\end{enumerate}

\noindent To install the NIDE:

\begin{enumerate}
\item Clone the repository into a repository directory.
\item From a shell running in your MetaC directory type make NIDE.
\item Add {\tt (load "$<$MetaC directory$>$/mc.el")} to your .emacs file.
\item Edit the first line of  mc.el to give the path to your gdb executable (the Gnu debugger).
\item Edit the second line of mc.el to give the path to your MetaC directory.
\item Start or restart Emacs. The file mc.el adds hooks such that it is safest to restart Emacs rather than load em.el into a running Emacs.
\end{enumerate}

\noindent The NIDE can be run on any file with extension .mc in any directory.  To experiment with the NIDE use Emacs to visit the file NIDE-examples.mc from the MetaC repository.  
Type C-M-s (control-meta-s) to start (or restart) the C kernel. Typing C-c C-c will run the cell containing the cursor and print
the result in a C comment at the bottom of the cell.  This is substantially equivalent to typing the cell contents into the REPL.
More Emacs key bindings and other features of the NIDE are described in section~\ref{sec:Emacs}.

\medskip
\noindent The following examples use the REPL.  However, all of these examples can be run as cells in the NIDE.

\subsection{Hello World}
\label{sec:hello}

\begin{verbatim}
bash$ make MC
...

bash$ MC

MC> `{hello world}

hello world

MC>
\end{verbatim}

In the above example the backquote expression given to the REPL macro-expands to a C expression which evaluates to the expression ``hello world''.
Backquote is described in more detail below.

\subsection{C Statements, C expressions, and Universal Syntax}

We can also declare global variables and execute statements from the REPL.

\begin{verbatim}
MC> int x[10];

done

MC> for(int i = 0; i < 10; i++)x[i] = i;

done


MC> for(int i = 0; i < 10; i++)fprintf(stdout,"%d",x[i]);

0123456789done

MC>int_exp(x[5])

5

MC>
\end{verbatim}

In C syntax one distinguishes C expressions from C statements.  A C
statement is executed for effect while a C expression is evaluated for
value. The REPL can be given either a statement or an expression.  When
given a C statement, the REPL simply prints ``done'' after executing
the statement.
When given a C expression the REPL computes and prints
the value.  The REPL assumes that the value of a C expression
is a universal syntax tree (also called an expression, giving a second, and confusing,
sense of the term ``expression''). The procedure {\tt int\_exp} above
converts an integer to a universal syntax expression.  Universal syntax expressions are abstract
syntax trees but can viewed as representations of strings.

If a C statement executes a {\tt return} outside of any
procedure then that value is returned to the REPL and printed.
For example, the above session can be extended with the following.

\begin{verbatim}
MC>{int sum = 0; for(int i = 0; i < 10; i++)sum += x[i]; return int_exp(sum);}

45

MC>
\end{verbatim}

\subsection{Definitions of Types and Procedures}

One can also define new data types and procedures from the REPL.

\begin{verbatim}

MC>typedef struct myexpstruct{
   char * label;
   struct myexpstruct * car;
   struct myexpstruct * cdr;} myexpstruct, *myexp;

done

MC> myexp mycons(char*s,myexp x,myexp y){
    myexp cell=malloc(sizeof(myexpstruct));
    cell->label=s;
    cell->car=x;
    cell->cdr=y;
    return cell;}

done

MC> expptr myexp_exp(myexp x){
   if(x==NULL)return string_atom("nil");
   return
    `{${string_atom(x->label)}
      ${myexp_exp(x->car)}
      ${myexp_exp(x->cdr)}};
}

done

MC> myexp_exp(mycons("foo",mycons("bar",NULL,NULL),NULL))


foo bar nil nil nil
MC>
\end{verbatim}

Procedures can also be redefined at the REPL provided that the
signature (argument types and return type) remains the same. Changing a procedure signature
requires restarting the MetaC REPL.  This restricting ensures
meaningful C type checking in the presence of dynamic linking.

\subsection{The Global Variable Array Restriction}

To simplify dynamaic linking, all global data
variables must be arrays. One can always use single element
arrays to represent non-array variables.  To make this more convenient
we allow single element arrays to be declared with an initial value in a
manner similar to non-array data variables.  For example, we can declare and assign a variable {\tt y}
as follows.

\begin{verbatim}
MC> int y[0] = 2;

done

MC> y[0] += 1;

done

MC> int_exp(y[0])

3

MC>
\end{verbatim}

Here assignments to $y[0]$ are allowed but assignments to $y$ are not --- assignment to array variables
are not allowed in $C$. As noted above, this restriction greatly simplifies dynamic linking of data variables.

\subsection{The Single Symbol Type Restriction}

To simplify the implementation of MetaC all type expressions appearing in procedure signatures and global array declarations must be single symbols.
Arbitrary types can be given single symbol names using {\tt typedef}.

\subsection{Backquote and Universal Syntax Expressions}

We now consider backquote and universal syntax expressions in more detail.  Backquote can be used in a manner analogous to string formatting.

\begin{verbatim}
MC> expptr friend[0] = `{Bob Givan};

done

MC> int height[0] = 6;

done

MC> `{My friend ${friend[0]} is ${int_exp(height[0])} feet tall.}

My friend Bob Givan is 6 feet tall.

MC> 
\end{verbatim}

While universal syntax expressions can be viewed as representations of strings, universal syntax
expressions are actually abstract syntax trees. The tree structure
plays an important role in pattern matching. The tree structure is
more apparent in the following example.

\begin{verbatim}
MC> expptr e[0] = `{a+b};

done

MC> `{bar(${e[0]})}

bar(a+b)

MC>
\end{verbatim}

As described in the next section, the pattern {\tt foo($\$$x)} will match the expression {\tt foo(a+b)} with {\tt x} bound to the expression (tree) {\tt a+b}.

\subsection{Pattern Matching}

MetaC provides a pattern matching case construct {\tt ucase} (universal case).
The general form of the case construct is

\begin{verbatim}
ucase{e;
  {<pattern1>}:{<body1>}
   ...
  {<patternn>}:{<bodyn>}}
\end{verbatim}

Variables are marked in patterns by the prefix $\$$.

\begin{verbatim}

MC>int numeralp(expptr x)
    {if(!atomp(x))return 0;
    char*s=atom_string(x);
    for(int i=0;s[i]!='\0';i++){if(s[i]<'0'||s[i]>'9')return 0;}
    return 1;
}

done

MC> int value(expptr e)
  {ucase
    {e;
      {$x+$y}:{return value(x)+value(y);}
      {$x*$y}:{return value(x)*value(y);}
      {($x)}:{return value(x);}
      {$z}.(numeralp(z)):{return atoi(atom_string(z));}
    }
  return 0; //this dead code convinces the compiler there is a return value.
  }

done

MC>int_exp(value(`{5+2*10}))

25

MC>int_exp(value(`{foo}))


 match error: the value 


foo
does not match any of


{$z}.(numeralp(z)){($x)}{$x*$y}{$x+$y}

MC>
\end{verbatim}

In many situations the choice of the particular tree structure imposed by the MetaC reader is not important as long as the same conventions are used in both the patterns and the expressions
they are matching.  For example, the expression {\tt a+b+c} will match the pattern
{\tt $\$$x+$\$$y+$\$$z} independent of whether + is left associative or right associative.  But the tree structure does matter in other cases.  The pattern {\tt $\$$x*$\$$y}
will not match the expression {\tt a+b*c} because the reader brackets {\tt a+b*c} as  $\fopen \mathtt{a~+} \fopen \mathtt{b * c} \fclose\fclose$. The pattern {\tt $\$$x*$\$$y} does match {\tt (a+b)*c}.
The variable {\tt $\$$any} is special.  It acts as a wild card and is not bound to a value.

When a {\tt ucase} is executed the patterns are tries sequentially and stops after the first match.  If no pattern matches an error is generated.
One can always add a final pattern of {\tt \{$\$$any\}} to provide a default
catch-all case if that is desired.

In release 1.0 repeated variables, such as in the pattern {\tt \{$\$$x + $\$$x\}}, are not supported (and not checked for).
If a variable is repeated it will be matched at its last occurrences under depth-first left to right traversal.

\subsection{Gensym and Macro Definitions}

MetaC supports computed macros which can exploit pattern matching, backquote pattern instantiation, and other (bootstrapped) high level language features.
As a very simple example we can define a {\tt dolist} macro at the REPL.

\begin{verbatim}

MC>umacro{mydolist($x,$L){$body}}{
   expptr rest=gensym("rest");
   return
    `{for(explist$rest=$L; cellp($rest);$rest=cdr($rest);){
      expptr$x=car($rest);
      $body}};
}

done

MC>macroexpand(`{mydolist(item,list){f(item);}})

for
  (explist _genrest33=list;
   cellp(_genrest33);
  _genrest33=cdr(_genrest33);
  ){expptr item=car(_genrest33);f(item);}

MC>
\end{verbatim}

The general form of a macro definition is
\begin{verbatim}
umacro{<pattern>}{<body>}
\end{verbatim}
where instances of {\tt <pattern>} in MetaC code are to be replaced by the value returned by {\tt <body>} under the variable bindings determined by the match.
The procedure {\tt macroexpand} takes a universal syntax expression
and returns the result of repeatedly expanding outermost macros until no further macro expansion is possible.  Macro expansion can generate effects as well as return an expansion.  The REPL performs
macro expansion on the given expression and also performs the effects of that expansion.  {\tt umacro} is itself a MetaC macro and we can feed the above macro definition to the REPL.

The macro expansion of the above macro definition defines a procedure to compute the macro expansion and installs that procedure on a macro property of the symbol {\tt mydolist}.
In a typical use a macro patterns is a symbol followed by a sequence of parenthesis expressions., in which case the expansion procedure is attached to the given symbol,
or generalized application expression or a binary connection expressions.  Universal syntax expression types are discussed in the next section.
The procedure for macro expansion is attached to either the head symbol of the application
or the binary operator of the binary connection expression.

\subsection{The Notebook IDE}
\label{sec:Emacs}

Starting the kernel with the key C-M-s creates a running C process.  When a cell is executed
with the command C-c C-c the text of the cell is (invisibly) passed to $C$ process by the process is
placed inside a comment below the cell.  If a comment already occurs directly below the cell this
comment is replaced by a new comment containing the response of the REPL.  As in a Jupyter notebook,
the values returned from the REPL are numbered so that one can see when the cell was executed
relative to other cell execution in the notebook.  If C-M-s is run when a kernel is already running
the kernel process is killed and a new one started (as in a Jupyter notebook).  When the kernel is
restarted the execution numbering is reset to start with 1.  Changing a procedure signature
(argument and return types) requires restarting the kernel.


\noindent {\bf Compile-Time Errors.}
If an error occurs while attempting to read or compile the cell expression an error statement is displayed --- typically the output of the C compiler --- and
an error message is printed in the code buffer as the value of cell.

\noindent {\bf Run Time Errors and Breakpoints.} The procedure {\tt berror(char *)} can be called from C code when a dynamic safety check fails.
MetaC primitives call {\tt berror} when safety checks fail.
When a {\tt berror} is called during execution gdb is entered in a interactive debugging REPL.  Giving the continue command to gdb will abort the cell execution and
return to the code buffer with the persistent C process intact.

The MetaC procedure {\tt breakpt(char *)} can be used for breakpoints from which execution can be continued.  When this procedure is called
gdb will be entered. Giving the continue command to gdb will continue from the breakpoint.

Segmentation faults are trapped by gdb directly.  In this case the
NIDE will move to the gdb REPL for investigating the error.  But
the normal gdb continue command will not return to the code buffer.
In this case typing {\tt print return\_to\_NIDE()} will in most cases
return to the code buffer with the persistent C process intact.  When
memory corruption is a possibility it is safest to restart the C
process.

\noindent {\bf Printing.} The procedure {\tt mcprint} is like {\tt fprintf} but omitting the file argument. The expression
{\tt mcprint("x = \%s$\backslash$n",s)} will print to the *Messages* buffer in Emacs. The expression {\tt mcpprint($e$)}
will pretty-print the expression $e$ to the *Messages* buffer.

\noindent {\bf Key Bindings.}  mc.el provides the following key bindings.

\begin{itemize}
\item[C-M-s] starts or restarts the persistent C process.

\item[C-c C-c] executes the cell containing the cursor.
  
\item[C-c C-r] executes all cells in the current region sequentially with a different execution number for each cell execution.

\item[C-M-a] moves to the begging of the current cell.

\item[C-M-p] moves to the beginning of the preceding cell.

\item[C-M-n] moves to the beginning of the next cell.

\end{itemize}

Executing the eLisp expression {\tt (MC:strip-cell-values)} in a code buffer will remove the cell values.  This is useful before a git commit as it can reduce or eliminate differences
in files between commits.

{\bf Include Statements.}  A cell in a code file containing {\bf #include(<filename>)} (with no semicolon) will load the cells of the named
file into the persistent C process.  The extension ".mc" will be automatically added and should not be explicitly given.

\section{Universal Syntax}

It is not obvious how to implement light weight expression quotation and expression pattern matching for C expressions.  The syntax of C is complex.
We bypass this complexity by introducing a syntax with the following three ``universal'' properties.

\begin{enumerate}
\item Universal syntax trees are semantics-free.  They are simply trees viewed as representations of character strings.

\item The universal syntax reader can read any parenthesis-balanced character string.
  Here parenthesis-balanced means that every open parenthesis, brace or bracket has a matching closing character and that string quotations
  are properly closed.
  
\item The printer inverts the reader. If we read a string $s$ into a universal syntax expression
  $e$ and then print $e$ back into a string $s'$ we have that $s$ and $s'$ are equivalent in a strong sense.  Here we want
  $s$ and $s'$ to be ``whitespace equivalent'' so as to be treated equivalently by the C lexer.
\end{enumerate}

The emphasis here is on the representation of strings.  The reader does not always invert the printer ---
the expression $\fopen \fopen \mathtt{one~two} \fclose \;\mathtt{three}\fclose$ prints as {\tt one two three} which reads as
$\fopen \mathtt{one}\; \fopen \mathtt{two~three} \fclose \fclose$.  But the represented string is preserved.  This is fundamentally different from
most programming languages supporting symbolic computation (such as Lisp) where it is assumed that the tree structure, rather than the represented string, is fundamental
and hence that the reader should invert the printer.

The above universality properties allow one to assign semantics to universal syntax expressions based on the strings that they represent.  We can assign C
semantics to an expression by printing the expression and passing the resulting string to a C compiler.  This string-based semantics is not always
compositional with respect to the universal syntax bracketing.  However, the tree structure imposed by the reader is designed to approximate the
compositional structure of C syntax.  In most cases pattern matching on universal syntax expressions recovers substructure that is semantically compositional under C
semantics. Parentheses and semicolons can be helpful in aligning universal syntax trees with C semantics.

\subsection{Universal Expressions: cons-car-cdr}

A universal syntax expression is either an atom (a wrapper around a string),
a pair $\fopen e_1 e_2 \fclose$ where $e_1$ and $e_2$ are expressions, or a ``parenthesis expression'' the form $(e)$,
$\{ e\}$, or $[e]$ where $e$ is an expression.   All three of these datatypes have the same C type {\tt expptr} (Expression Pointer).
Each has a constructor procedure, a predicate, and accessor functions.  The constructor, predicate and accessors for atoms, pairs and parenthesis expressions
are the following.
The atom data type has the constructor, test and accessor function for atoms are the following.

\begin{verbatim}
expptr string_atom(char *);
int atomp(expptr);
char * atom_string(expptr); //the argument must be an atom.

expptr cons(expptr,expptr);
int cellp(expptr);
expptr car(expptr); //the argument must be a cell. returns the first component.
expptr cdr(expptr); //the argument must be a cell. returns the second component.

expptr intern_paren(char,expptr); // the char must be one of '(', '{' or '['
int parenp(expptr);
expptr paren_inside(expptr);
\end{verbatim}

\subsection{Universal Expressions: Phantom Brackets}

The MetaC reader maps a character string to a universal syntax expression.  A specification of the reader is given in section~\ref{sec:reader}.
The expression produced by the reader
can be represented by ``phantom brackets'' around the given string
where there is a pair of brackets for each cons cell.
For example the expression \mtt{\{one two three\}} reads as $\{\fopen \mathtt{one}\;\fopen \mathtt{two~three}\fclose \fclose\}$.
Examples of strings and the phantom bracking imposed by the reading those strings is given in figure~{ref{fig:reader}}.
The printer simply removes the phantom brackets and prints the string that the expression represents.

To reduce the clutter of brackets we will adopt two conventions for supressing brackets when exhibiting phantom brackets.
The first convention is the Lisp right-branching convention of not showing all the cell brackets for right-associative (right-branching) sequences.
For example $\fopen \mathtt{zero}\;\fopen \mathtt{one}\;\fopen \mathtt{two~three}\fclose \fclose \fclose$.
will be written as $\fopen\mathtt{zero~one~two~three}\fclose$.  Note that these ``lists'' are atom-terminated rather than the Lisp convention of
nil termination.

The second convention is that we will sometimes write $\fopen \fopen a_1 \;o\fclose\;a_2\fclose$ where $o$ is a connective atom
as the left-branching structure $\fopen a_1\;o\;a_2 \fclose$.  For example, the expression \mtt{\{a + b\}} reads as
$\{\fopen \fopen \mathtt{a~+} \fclose \;\mathtt{b} \fclose \}$ which is then abbreviated as
$\{\fopen \mathtt{a~+~b} \fclose \}$.  Left-branching for binary connectives gives a
C-consistent treatment of semicolon as a binary connective while also supporting the interpretation of semicolon as a statement terminator.
This is discussed in more detail below.

It will generally be clear from context whether we using the Lisp right-branching list convention
or the left-branching connective convention.
A set of examples of strings and the phantom brackets generated by the reader is given in figure~\ref{fig:reader}.


To emphasize the significance of left-branching binary connectives we note that
the MetaC reader bracketing of
$$\{e_1\;;\;e_2\;;\;e_3\;;\;e_4\}$$
can be written using either the left-braching binary connective convention as
$$\{\fopen e_1\;;\;\fopen e_2\;;\;\fopen e_3\;;\;e_4\fclose\fclose\fclose\}$$
or the right-braching sequence convention as
$$\{\fopen \fopen e_1\;;\fclose \;\fopen e_2\;;\fclose \;\fopen e_3\;;\fclose\;e_4\fclose\},$$
both of which abbreviate the same full bracketing
$$\{\fopen \fopen e_1\;;\fclose \;\fopen \fopen e_2\;;\fclose \;\fopen \fopen e_3\;;\fclose\;e_4\fclose\fclose\fclose\}.$$

\begin{figure}
\begin{eqnarray*}
  \mathtt{Hello~World} & \Rightarrow & \fopen \mathtt{Hello}\;\; \mathtt{World}\fclose \\
  \mathtt{one~two~three} & \Rightarrow & \fopen \mathtt{one}\;\; \fopen \mathtt{two} \; \;\mathtt{three}\fclose\fclose \\
   & = & \fopen \mathtt{one~two~three} \fclose \\
  \mathtt{x~+~y} & \Rightarrow & \fopen\fopen \mathtt{x~+}\fclose\;\mathtt{y}\fclose \\
  & = & \fopen \mathtt{x~+~y} \fclose \\
  \mathtt{x+y*z} & \Rightarrow & \fopen \mathtt{x~+}\; \fopen \mathtt{y~*~z} \fclose\fclose \\
  \mathtt{(x+y)*z} & \Rightarrow & \fopen (\fopen \mathtt{x~+~y} \fclose )\;\mathtt{*~z}\fclose \\
  \mathtt{foo}(\mathtt{int~x}) & \Rightarrow & \fopen \mathtt{foo}\; (\fopen \mathtt{int}\;  \; \mathtt{x}\fclose)\fclose \\
  \mathtt{foo(int~x,~float~y)} & \Rightarrow & \fopen \mathtt{foo} \; (\fopen\fopen \mathtt{int}\; \mathtt{x} \fclose\;
  \mathtt{,}\; \fopen\mathtt{float} \; \mathtt{y} \fclose\fclose )\;\fclose
\end{eqnarray*}

\caption{{\bf Examples of Reader Bracketings.} Bracketings are shown for the expression that results form reading the given strings.
  A complete bracketing shows a pair of brackets for every expression pair (cons cell).
  The second and third example show two somewhat informal conventions for dropping some of the brackets --- general sequences are
  assumed to be right-associative and binary connective applications are assumed to be left-associative.  These conventions are used in other examples.
  Expressions are printed without the brackets --- the brackets are ``phantoms'' that show the tree structure.   The bracketing (parsing) done by the reader
  is specified formally in section~\ref{sec:reader}. Since the bracketing does not affect the represented string, the precise bracketing is often unimportant.}
\label{fig:reader}
\end{figure}


\subsection{The Reader Specification}
\label{sec:reader}

The MetaC reader can be described in three phases --- preprocessing, lexicalization, and parsing.

The MetaC preprocessor removes C-style comments and divides files into segments where each segment is to be read as a separate expression.
A new segment starts at the beginning of any line whose first character is not a space, tab or close character (right parenthesis, brace or bracket).
A file must be parenthesis-balanced within each segment.
For the REPL a segment ends at the first return character not occurring inside parentheses.

Lexicalization segments a pre-processed character sting into to a sequence of atoms.
The MetaC lexer preserves all non-white characters.  For the MetaC lexer each atom is one of the following.

\begin{itemize}
\item Symbols,  A symbol is a character string consisting of only alpha-numeric characters --- upper and lower case letters of the alphabet, plus the decimal numerals, plus underbar.
  For example {\tt foo\_bar1}.
\item Connectives.  A connective is a character string consisting of only ``connective characters'' --- the connective characters consist of all non-alphanumeric, non-white, non-parenthesis, characters
  other than the three special characters {\tt \$}, {\tt `} and $\backslash$.
\item Quoted strings.  A character string starting and ending with the same string quotation character.  For example {\tt "foo bar"}, {\tt "!:\&?;"} or {\tt 'a'}.
\item Single character atoms for parenthesis characters and the three special characters $\mtt{`}$, $\mtt{\$}$, and $\backslash$.
\end{itemize}

Two strings will be called whitespace-equivalent if they lexicalize to the same sequence of atoms.
Two strings that lexicalize equivalently under the MetaC lexer will also lexicalize equivalently under the C lexer.

\newcommand{\sym}{\mathrm{SYM}}
\newcommand{\conn}{\mathrm{CONN}}
\newcommand{\quot}{\mathrm{QUOTE}}
\newcommand{\misc}{\mathrm{MISC}}
\newcommand{\app}{\mathrm{APP}}
\newcommand{\var}{\mathrm{VAR}}



The reader is specified by a the grammar shown in figure~\ref{fig:grammar}.
To simplify the specification of the reader we enclose the given string in parentheses so that, without loss of generality, the input is assumed to be of the form
$\{s\}$ where $s$ is the lexical sequence to be read.  The grammar has a nonterminal $P$ for parenthesis expression which we take as the top level nonterminal.
The nonterminals $\sym$ and $\quot$ range over alpha-numeric string atoms and quoted string atoms respectively.
For each positive integer $p$ we have a nonterminal $\conn_p$ ranging over connective atoms of precedence $p$.
We have a nonterminal $E_p$ for expressions formed with connectives
of precedence $p$.  We also has a nonterminal $E_\infty$ for expressions that are formed at higher precedence than any connective expression.
The precedence levels are divided into a set ${\cal L}$ of left-associative precedence levels and a set ${\cal R}$ of right associative precedence levels.
There is a special precedence level 3 for combining expressions with the ``null connective''. The null connective is left-associative.
The null connective is higher precedence that semicolon and comma but lower precedence than all other connectives.
The nonterminal $E_\infty$ includes an epsilon production allowing null arguments.

\begin{figure}
  
\begin{eqnarray*}
  P & ::= & (E_p) \;|\; \{E_p\} \;|\; [E_p] \\
  E_p & ::= & \fopen \fopen E_\ell\;\conn_p\fclose \;E_r\fclose\;\;\;\;p \in {\cal R}, \;\ell > p, \; r \geq p \\
  E_p & ::= & \fopen \fopen E_\ell\;\conn_p\fclose \;E_r\fclose\;\;\;\;p \in {\cal L}, \; \ell \geq p,\; r > p \\
  E_3 & ::= & \fopen E_\ell \;E_r\fclose \;\;\;\ell > 3,\;r \geq 3\\
  E_\infty & ::= & \quot \;|\; \fopen S \; \;P^* \fclose \;|\; \fopen `\;P\fclose \;|\; P \;|\; \epsilon \;|\; \mathrm{JUNK}\\
  S & ::= & \;\sym \;|\; V \\
  V & ::= & \fopen \$\;\sym\fclose \;|\; \fopen \$\;P\fclose \;|\; \fopen \backslash \; V \fclose\\
  P^* & ::= &  \epsilon  \;|\; \fopen P\;P^* \fclose \\
  \mathrm{JUNK} & ::= & ` \;|\; \mathrm{SJUNK} \\
  \mathrm{SJUNK} & :: = & \$ \;|\;  \backslash \;|\; \fopen \backslash\;\mathrm{JUNK} \fclose\\
\end{eqnarray*}

\caption{{\bf The grammar defining the MetaC reader.} The input string is assumed to be of the form $(s)$ so that endpoints are explicitly labeled.
The nonterminal $\sym$ generates non-empty alpha-numeric strings; $\conn_p$ generates non-empty connective
strings of precedence $p$; and $\quot$ generates string quotations.  ${\cal R}$ is a set of right-associative precedence levels and ${\cal L}$ is a set of left-associative levels.
Only the highest precedence level is left-associative. MetaC classifies all printable ASCII characters as being either alpha-numeric, connective, string quotations, parenthesis characters or one of the three special characters
{\tt `}, $\$$ or $\backslash$.
The reader will accept any parenthesis-balanced string. $\epsilon$ denotes the empty string. Generated cells of the form $\fopen w\;\epsilon \fclose$ or $\fopen \epsilon \;w\fclose$ are replaced by $w$.
Although the grammar is ambiguous, the reader is deterministic as specified by the constraints that
$E_\infty$ expressions must be maximal and that the use of the $\epsilon$ production for $E_\infty$ must be minimized.  See the text for details.
  }
\label{fig:grammar}
\end{figure}

The nonterminal $S$ ranges over symbols or variables where $V$ ranges over variables.  Variables are handles specially in pattern matching ({\tt ucase}) and pattern instantiation (backquote).
Expression of the form $\fopen S\;P^*\fclose$ include {\tt foo}, {\tt foo(x)}, {\tt foo(int x)\{return x;\}},
{\tt \$x}, {\tt \$f(x)}, and {\tt \$\{f(x)\}}.


The above grammar is ambiguous.  For example the string {\tt \{foo (a) (b)\}} can be parsed as either the left-branching structure $\{\fopen\fopen\sym\;P^*\fclose\;P\fclose\}$
or the  right-branching structure $\{\fopen\sym\;P^*\fclose\}$.
The reader is of course deterministic --- {\tt \{foo (a) (b)\}} is read as right-branching.  While a deterministic grammar for the reader can be given, it is simpler
to specify a deterministic parsing process for the above ambiguous grammar.
The implementation runs a deterministic left-to-right shift-reduce process.
However, the parser is easier to specify as operating in global stages.  In the first stage one identifies all maximal $E_\infty$ substrings.
The maximal $E_\infty$ requirement specifies that {\tt \{foo (a) (b)\}} is parsed as a single (right-branching)
$E_\infty$ expression. However the string {\tt \{$\$$\;foo\;(a)\;(b)\}} is read as the longer $E_\infty$ expression $\{\fopen \fopen \mathtt{!~foo}\fclose\ \fopen \mathtt{(a)~(b)} \fclose \fclose$.
The grammar does have the property that any given string has a unique segmentation into maximal $E_\infty$ expressions each of which has a unique structure.

After identifying maximal $E_\infty$ expressions we are left with a sequence of arguments (the $E_\infty$ expressions) and connectives.
However, it is possible that this sequence contains multiple consecutive connectives or multiple consecutive arguments.  We then place an argument between any two consecutive
connectives using the $\epsilon$ production for $E_\infty$ and also add an $\epsilon$ term at the beginning of the sequence if the sequence starts with a connective and an
epsilon argument at the end if the sequence ends in a connective.  We now have a sequence of arguments and connectives starting and ending with arguments and where there
are no two consecutive connectives.  Next set $k$ to be the largest precedence of any connective and form all the $E_k$ substrings. We then repeatedly decrement $k$ and identify all the $E_k$ substrings
until we have identifies all $E_p$ substrings for all $p$.  At this point the entire string must be parsed as $E_p$ where $p$ is the smallest precedence of the connectives
where we think of adjacent arguments as having an implicit precedence 3 connetive between them.

\noindent This process can parse any parenthesis-balanced string.

The above specification of the reader can result in cells of the form $\fopen e\;\epsilon \fclose$ or $\fopen \epsilon \;e\fclose$.   The implementation avoids producing such cells
and the reader can be viewed as replacing $\fopen e\;\epsilon \fclose$ or $\fopen \epsilon \;e\fclose$ by $e$ so that
all cells are of the form $\fopen e_1\;e_2\fclose$ where $e_1$ and $e_2$ are expressions representing non-empty strings.  An empty parenthesis string {\tt ()}
is read as a parenthesis expression containing an atom for the empty string.

\noindent Grouped by precedence, the binary connective characters are

\medskip
\centerline{\{\mtt{;}\} \{\mtt{,}\}  \{\mtt{|}\} \{$\epsilon$\}
  \{{\tt \&}, {\tt ?}, {\tt !}\} \{{\tt =} {\tt $\sim$}, {\tt $<$}, {\tt $>$}\} \{{\tt +}, {\tt -}\}
  \{{\tt *}, {\tt /}\} \{{\tt \%}, $\hat{~}$, {\tt .}\} \{\mtt{:},  {\tt @}, {\tt \#}\}.}

\noindent The precedence of a binary connective is determined by its first character.  The
characters have low to high (outer to inner) precedence in the order given with symbols in the same
group having the same precedence.  Here $\epsilon$ represents the null connective at precedence
level 3.  The precedence can be summarized in outer to inner order as semicolon, comma, bar, the
null connective, Boolean connectives, binary predicates, three levels of binary functions, and
innermost connectives which can be viewed as providing a way of building structured atoms.  This
universal syntax precedence conventions has
various divergences with C syntax.  However, when writing a macro package in MetaC one can simply
adopt the MetaC precedence conventions for the source code and use parentheses where necessary in
the generated C code.

\subsection{Backquote and Pattern Matching Revisited}

The semantics of backquote is defined in terms of cons-car-cdr view of expressions independent of the MetaC reader.
In the typical case, the C value of a backquote expression
$\fopen ` \;\{e\}\fclose$ is the expression (tree) $e$ with subexpressions (subtrees) of the form $\fopen \$\;x \fclose$, where $x$ is a symbol,
replaced by the C value of $x$
and subexpressions (subtrees) of the form $\fopen \$\;\{w\}\fclose$ replaced by the expression which is the C value of the string represented by the expression $w$.

Unfortunately this evaluation rule for backquote expressions is incomplete.  One of the most
confusing situations is where the expansion of a macro contains a backquote.  Writing such a macro typically involves nested backquotes.  While nested backquotes
are confusing, and should be avoided when possible, MetaC supports nested backquotes.  We consider a series of backquote expressions each of which evaluates to the previous one.

First we have
\begin{equation}
\label{bq1}
`\{a+b+\$\{z\}\}
\end{equation}

If the value of variable {\tt z} is the expression {\tt c} then the value of expression (\ref{bq1}) is the expression {\tt a+b+c}.
The symbol {\tt \$} can be included in the value of a backquote expression by quoting it.  This gives our second expression.
\begin{equation}
\label{bq2}
`\{`\{a + \$\{y\} + \backslash\$\{z\}\}\}
\end{equation}

If the value of variable {\tt y} is the expression $b$ then the value expression of (\ref{bq2}) is expression (\ref{bq1}).
We can even have multiple layers of quotation as in the following.
\begin{equation}
\label{bq3}
`\{`\{`\{\$\{x\} + \backslash\$\{y\} + \backslash\backslash\$\{z\}\}\}\}
\end{equation}

If the value of variable {\tt x} is the expression {\tt a} then the value of expression (\ref{bq3}) is expression (\ref{bq2}).

As with backquote, pattern matching is defined in terms of the cons-car-cdr view of expressions independent of the MetaC reader.  We define a substitution to be a mapping from
symbol atoms to expressions. For a substitution $\sigma$ and a pattern $\{e\}$ we define the expressions $\sigma(e)$
to be the result of replacing each subexpression (subtree) of $e$ of the form $\fopen \$\;x \fclose$ where $x$ is a symbol atom with $\sigma(x)$.  A pattern expression (tree) $\{e\}$ matches an expression (tree) $w$ with substitution $\sigma$
if $\sigma(e) = w$. An exception to this is the case where a variable occurs multiple times in the pattern.  In release 1.0 multiple occurrences of a variable in a pattern is not supported.

\section{Expression Interning, Expression Properties and Undo Frames}

In MetaC expressions are interned.  This means that two expressions which print as the same strings will be represented by the same data structure with the same meory address (the same pointer).
Hence we have

\begin{verbatim}
MC> int_exp(`{foo(a)} == `{foo(a)})
1
\end{verbatim}

Expressions also have property lists.  The expression

\centerline{\tt setprop($e$,$p$,$v$)}

sets the property $p$ of expression $e$ to the value $v$ where $p$ and $v$ are also expressions.
The expression

\centerline{\tt getprop($e$,$p$,$v$)}

returns property $p$ of expression $e$ or the expression $v$ if no $p$-property has been assigned to $e$.
C coersions can be used to store property values other than expressions
but this raises the standard safety issues of C type coercions.  It is not difficult to define macros supporting properties of different types, but this has not been done in release 1.0.

Interned expressions with properties provide the functionality of dictionary data structures such as C++ hashmaps or Python dictionaries.
They also facilitate bottom-up logic programming implementations of dynamic programming inference algorithms.

\noindent {\bf Undo Frames.} Creating expressions and setting properties allocates memory.  However this allocation is ``undone'' on exit from an ``undo frame''.
The statement {\tt push\_undo\_frame();} enters an undo frame and the expression {\tt return\_from\_undo($e$)} exits the undo frame returning the value
of the expression $e$.  All expression allocation and property setting that occurs in an undo frame is undone on exit from the frame.  The expression value $e$
returned from the frame is copied into an ephemeral return memory before the undoing occurs, is then copied into the parent undo frame after the undoing
and that copy in the parent frame is returned as the value of the return expression.  This undo architecture facilitates the implementation of case-analysis
in automated reasoning systems such as SMT solvers.  It also provides a very efficient form of memory management analogous to, but quite different from,
stack allocation.

\section{The MetaC Primitives}

We now give a list of the MetaC primitives and pre-installed type definitions.  The macros backquote, ucase, and umacro expand to code built on these primitves.
We start with type definitions needed for the single atom type restriction needed for the limiting type parsing abilities of MetaC.

\begin{verbatim}

typedef char * charptr;

typedef void * voidptr;

typedef FILE * FILEptr;

\end{verbatim}

Next we have the lowest level interface functions for expressions.  The macros {\tt backquote} and {\tt ucase} expand into C code using these procedures.

\begin{verbatim}
typedef struct expstruct{...}*expptr;

expptr string_atom(char * s);

int atomp(expptr e);

charptr atom_string(expptr a);

expptr cons(expptr x, expptr y);

int cellp(expptr e);

expptr car(expptr x);

expptr cdr(expptr x);

expptr intern_paren(char openchar, expptr arg); \\ openchar must be one of '(', '{' or '['.

int parenp(expptr e);

expptr paren_inside(expptr e);

char constructor(expptr e); //used for paren expressions.
\end{verbatim}

We also have integer-expression conversions.  The REPL and NIDE require that inputs and cells are expression-valued.

\begin{verbatim}
expptr int_exp(int i);

int exp_int(expptr s);
\end{verbatim}

Next we have expression properties.  The macro {\tt umacro } expands to code that
sets the macro property of some atom to a procedure pointer.  Gensym is also important
in macro definitions.

\begin{verbatim}
void setprop(expptr e, expptr key, expptr val);

expptr getprop(expptr e, expptr key, expptr defaultval);

expptr gensym(char * s);
\end{verbatim}

We also have error exceptions and break points.

\begin{verbatim}
void berror(charptr s);

void breakpt(charptr s);
\end{verbatim}

We now consider reading and printing.  The procedure {\tt file\_expressions} takes a file name and returns a list of the expressions
(in universal syntax) contained in the file.  The last two print to the *Messages* buffer in emacs in the NIDE.
The last expressions is a macro.

\begin{verbatim}
expptr file_expressions(char *name);

void pprint(expptr e, FILEptr f, int indent); //indent is typically 0

void mcpprint(epptr e);

void mcprint(...)
\end{verbatim}

We have the following two macro-expansion procedures.  The first does full macro expansion --- the result is guaranteed not to contain macros.
The second does one step of macro expansion --- the result may contain more macros.

\begin{verbatim}
expptr macroexpand(expptr e);

expptr macroexpand1(expptr e); //this result may contain unexpanded macros
\end{verbatim}

We also have the following list-processing procedures and macros.

\begin{verbatim}
expptr append(expptr l1, expptr l2);

expptr reverse(expptr l);

typedef  expptr exp_to_exp(expptr);
typedef  void exp_to_void(expptr);

expptr mapcar(exp_to_exp f, expptr l);

void mapc(exp_to_void f, expptr l);

int length(expptr l);
\end{verbatim}

Finally we have the procedures related to undo frames.

\begin{verbatim}
void push_undo_frame();

void return_from_undo(expptr e);

void undo_set(voidptr loc, voidptr val);

voidptr undo_alloc(int size);
\end{verbatim}

\bibliographystyle{abbrv}

\bibliography{manual}

\end{document}
